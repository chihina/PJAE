data: 
  name: volleyball
  sendo_dataset_dir : data/volleyball_tracking_annotation
  rgb_dataset_dir : data/videos
  annotation_dir : data/vatic_ball_annotation/annotation_data/
  dataset_bbox_gt: data/jae_dataset_bbox_gt
  dataset_bbox_pred: data/jae_dataset_bbox_pred

exp_set:
  save_folder: saved_weights
  wandb_log : False

  wandb_name: debug

  batch_size: 2
  num_workers: 2
  seed_num: 777
  gpu_mode : True
  gpu_start : 6
  gpu_finish : 6

  resize_height : 320
  resize_width : 640
  resize_head_width: 64
  resize_head_height: 64

exp_params:

  use_person_person_att_loss : False
  # use_person_person_att_loss : True
  person_person_att_loss_weight : 1

  # use_person_person_jo_att_loss : False
  use_person_person_jo_att_loss : True
  person_person_jo_att_loss_weight : 1

  # use_person_scene_att_loss : False
  use_person_scene_att_loss : True
  person_scene_att_loss_weight : 1

  use_person_scene_jo_att_loss : False
  # use_person_scene_jo_att_loss : True
  person_scene_jo_att_loss_weight : 1

  # use_final_jo_att_loss : False
  use_final_jo_att_loss : True
  final_jo_att_loss_weight : 1

  use_frame_type: mid
  # use_frame_type: all

  # bbox_types: GT
  # bbox_types: PRED

  # gaze_types: GT
  gaze_types: PRED
  
  # action_types: GT
  action_types: PRED

  # position augmentation
  use_position_aug: False
  # use_position_aug: True
  position_aug_std: 0.05

  # loss function
  loss : mse
  # loss : bce

  # learning rate
  lr : 0.00001
  # lr : 0.0001
  # lr : 0.001
  # lr : 0.01
  # lr : 0.1
  
  # gt gaussian
  # gaussian_sigma: 40
  gaussian_sigma: 10
  # gaussian_sigma: 5

  # learning schedule
  nEpochs : 500
  start_iter : 0
  snapshots : 100
  scheduler_start : 1000
  scheduler_iter : 1100000

  # pretrained models
  pretrained_models_dir: saved_weights

  # use_pretrained_head_pose_estimator: False
  use_pretrained_head_pose_estimator: True
  pretrained_head_pose_estimator_name: volleyball-head_pose_estimator
  # freeze_head_pose_estimator: False
  freeze_head_pose_estimator: True

  # use_pretrained_saliency_extractor: False
  use_pretrained_saliency_extractor: True
  # pretrained_saliency_extractor_name: pretrained_scene_extractor_davt
  # pretrained_saliency_extractor_name: volleyball-dual-mid_p_p_field_middle_p_s_davt_bbox_GT_gaze_GT_act_GT_p_s_only
  pretrained_saliency_extractor_name: volleyball-dual-mid_p_p_field_middle_p_s_davt_bbox_PRED_gaze_PRED_act_PRED_p_s_only
  freeze_saliency_extractor: False
  # freeze_saliency_extractor: True

  # use_pretrained_joint_attention_estimator: False
  use_pretrained_joint_attention_estimator: True
  # pretrained_joint_attention_estimator_name: volleyball-dual-mid_p_p_field_middle_bbox_GT_gaze_GT_act_GT
  pretrained_joint_attention_estimator_name: volleyball-dual-mid_p_p_field_middle_bbox_PRED_gaze_PRED_act_PRED_ind_only
  # pretrained_joint_attention_estimator_name: volleyball-dual-mid_p_p_field_middle_bbox_PRED_gaze_PRED_act_PRED_token_only
  # pretrained_joint_attention_estimator_name: volleyball-dual-mid_p_p_field_middle_bbox_PRED_gaze_PRED_act_PRED_ind_and_token_ind_based
  # pretrained_joint_attention_estimator_name: volleyball-dual-mid_p_p_field_middle_bbox_PRED_gaze_PRED_act_PRED_ind_and_token_token_based
  freeze_joint_attention_estimator: False
  # freeze_joint_attention_estimator: True

model_params:
  model_type: ja_transformer_dual

  # Position
  # use_position : False
  use_position : True

  # Gaze
  # use_gaze : False
  use_gaze : True

  # Action
  use_action : False
  # use_action : True

  # Person embedding
  # head_embedding_type : liner
  head_embedding_type : mlp

  # Whole image
  # use_img : False
  use_img : True

  # person-person transformer
  people_feat_dim : 16
  # people_feat_dim : 32
  # use_people_people_trans: False
  use_people_people_trans: True
  # people_people_trans_enc_num : 1
  people_people_trans_enc_num : 2
  # people_people_trans_enc_num : 3
  # people_people_trans_enc_num : 4
  # mha_num_heads_people_people : 1
  mha_num_heads_people_people : 2
  # mha_num_heads_people_people : 4
  # mha_num_heads_people_people : 8
  # mha_num_heads_people_people : 16
  
  # p_p_estimator_type : fc_shallow
  # p_p_estimator_type : fc_middle
  # p_p_estimator_type : fc_deep
  # p_p_estimator_type : deconv_shallow
  # p_p_estimator_type : deconv_middle
  # p_p_estimator_type : deconv_deep
  # p_p_estimator_type : field_shallow
  p_p_estimator_type : field_middle
  # p_p_estimator_type : field_deep

  p_p_aggregation_type : ind_only
  # p_p_aggregation_type : token_only
  # p_p_aggregation_type : ind_and_token_ind_based
  # p_p_aggregation_type : ind_and_token_token_based

  # rgb-person transformer
  rgb_feat_dim : 256
  rgb_people_trans_enc_num : 1
  mha_num_heads_rgb_people : 1

  # rgb_cnn_extractor_type : rgb_patch
  # rgb_patch_size : 8
  # rgb_cnn_extractor_type : resnet18
  rgb_cnn_extractor_type : resnet50
  # rgb_cnn_extractor_stage_idx : 1
  # rgb_cnn_extractor_stage_idx : 2
  # rgb_cnn_extractor_stage_idx : 3
  rgb_cnn_extractor_stage_idx : 4

  p_s_estimator_type : davt
  # p_s_estimator_type : transformer
  # p_s_estimator_type : cnn
  p_s_estimator_cnn_pretrain : False
  # p_s_estimator_cnn_pretrain : True
  use_p_s_estimator_att_inside : False
  # use_p_s_estimator_att_inside : True

  # fusion_net_type : early
  # fusion_net_type : mid
  # fusion_net_type : late
  # fusion_net_type : scalar_weight
  fusion_net_type : simple_average
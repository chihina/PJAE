data: 
  name: videocoatt
  dataset_dir : data/VideoCoAtt_Dataset
  saliency_dataset_dir : data/deepgaze_output_loader

exp_set:
  save_folder: saved_weights
  wandb_log : True

  # wandb_name: videocoatt-dual-people_fc_shallow
  # wandb_name: videocoatt-dual-people_fc_middle
  # wandb_name: videocoatt-dual-people_fc_deep
  # wandb_name: videocoatt-dual-people_deconv_shallow
  # wandb_name: videocoatt-dual-people_deconv_middle
  wandb_name: videocoatt-dual-people_field_middle
  # wandb_name: videocoatt-dual-people_field_deep

  # batch_size: 16
  batch_size: 8
  # batch_size: 2
  num_workers: 16
  seed_num: 777
  gpu_mode : True
  gpu_start : 2
  gpu_finish : 2

  resize_height: 320
  # resize_width: 480
  resize_width: 640
  resize_head_height: 224
  resize_head_width: 224

exp_params:
  use_person_person_att_loss : False
  # use_person_person_att_loss : True
  person_person_att_loss_weight : 1

  # use_person_person_jo_att_loss : False
  use_person_person_jo_att_loss : True
  person_person_jo_att_loss_weight : 1

  use_person_scene_att_loss : False
  # use_person_scene_att_loss : True
  person_scene_att_loss_weight : 1

  use_person_scene_jo_att_loss : False
  # use_person_scene_jo_att_loss : True
  person_scene_jo_att_loss_weight : 1

  use_final_jo_att_loss : False
  # use_final_jo_att_loss : True
  final_jo_att_loss_weight : 1

  use_frame_type: mid
  # use_frame_type: all

  use_gt_gaze: False
  # use_gt_gaze: True

  # position augmentation
  use_position_aug: False
  # use_position_aug: True
  position_aug_std: 0.05

  # loss function
  loss : mse
  # loss : bce

  # learning rate
  lr : 0.0001

  # gt gaussian
  gaussian_sigma: 10

  # learning schedule
  nEpochs : 500
  start_iter : 0
  snapshots : 100
  scheduler_start : 1000
  scheduler_iter : 1100000

  det_heads_model : dets_txt_nk_faster_rcnn_20220421
  # train_det_heads : False
  train_det_heads : True
  train_heads_conf : 0.6
  test_heads_conf : 0.6

  # pretrained models
  pretrained_models_dir: saved_weights

  # use_pretrained_head_pose_estimator: False
  use_pretrained_head_pose_estimator: True
  # pretrained_head_pose_estimator_name: videocoatt-head_pose_estimator
  pretrained_head_pose_estimator_name: gazefollow-dual-cnn-w_pre
  # pretrained_head_pose_estimator_name: videoattentiontarget-dual-cnn_wo_pre_w_att_ins
  # freeze_head_pose_estimator: False
  freeze_head_pose_estimator: True

  use_pretrained_saliency_extractor: False
  # use_pretrained_saliency_extractor: True
  # pretrained_saliency_extractor_name: pretrained_scene_extractor_davt
  pretrained_saliency_extractor_name: gazefollow-dual-cnn-w_pre
  # pretrained_saliency_extractor_name: videoattentiontarget-dual-cnn_wo_pre_w_att_ins
  freeze_saliency_extractor: False
  # freeze_saliency_extractor: True

  use_pretrained_joint_attention_estimator: False
  # use_pretrained_joint_attention_estimator: True
  pretrained_joint_attention_estimator_name: pretrain_head_estimator
  freeze_joint_attention_estimator: False
  # freeze_joint_attention_estimator: True

model_params:
  model_type: ja_transformer_dual_only_people

  # Position
  # use_position : False
  use_position : True

  # Gaze
  # use_gaze : False
  use_gaze : True

  # Action
  use_action : False
  # use_action : True

  # Person embedding
  # head_embedding_type : liner
  head_embedding_type : mlp

  # Whole image
  # use_img : False
  use_img : True

  # person-person transformer
  people_feat_dim : 16
  # use_people_people_trans: False
  use_people_people_trans: True
  people_people_trans_enc_num : 2
  mha_num_heads_people_people : 2
  # p_p_estimator_type : fc_shallow
  # p_p_estimator_type : fc_middle
  # p_p_estimator_type : fc_deep
  # p_p_estimator_type : deconv_shallow
  # p_p_estimator_type : deconv_middle
  # p_p_estimator_type : deconv_deep
  # p_p_estimator_type : field_shallow
  p_p_estimator_type : field_middle
  # p_p_estimator_type : field_deep  

  # p_p_aggregation_type : ind_only
  p_p_aggregation_type : token_only
  # p_p_aggregation_type : ind_and_token_ind_based
  # p_p_aggregation_type : ind_and_token_token_based

  # rgb-person transformer
  rgb_feat_dim : 256
  rgb_people_trans_enc_num : 1
  mha_num_heads_rgb_people : 1

  # rgb_cnn_extractor_type : rgb_patch
  # rgb_patch_size : 8
  # rgb_cnn_extractor_type : resnet18
  rgb_cnn_extractor_type : resnet50
  # rgb_cnn_extractor_stage_idx : 1
  # rgb_cnn_extractor_stage_idx : 2
  # rgb_cnn_extractor_stage_idx : 3
  rgb_cnn_extractor_stage_idx : 4

  p_s_estimator_type : davt
  # p_s_estimator_type : transformer
  # p_s_estimator_type : cnn
  p_s_estimator_cnn_pretrain : False
  # p_s_estimator_cnn_pretrain : True
  # use_p_s_estimator_att_inside : False
  use_p_s_estimator_att_inside : True

  # fusion_net_type : early
  # fusion_net_type : mid
  # fusion_net_type : late
  fusion_net_type : simple_average
  # fusion_net_type : scalar_weight